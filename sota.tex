\chapter{State of the art}

Since the resolution of elliptic problems is a building block for a lot of different numerical methods, the amount of work put into efficient solvers has been huge, both in the academical and the industrial domains. This means that the available literature on the subject is equally massive. This chapter attempts to give the reader a snapshot of the different methods used in practice to solve Poisson's equation with trillions of unknowns.

Let us first note that it is impossible to define the most efficient method since it depends a lot on the geometry of the computational domain and on the source term (i.e. the right-hand side in Poisson's equation). Therefore, we will show different algorithms and explain what their strengths and weaknesses are. 

Let us also note that, for all the methods presented here, the high-order version of the method is almost always a better choice than the low-order counterpart if we want to reach a given accuracy. As explained in the introduction chapter, this is because high order methods have a better accuracy for an equivalent number of unknowns. The only exception to this rule is if we only need a rather low accuracy in the solution.  

We can divide the solvers into two large categories : basic solvers that resulted from earlier work and high-end solvers that are the implementation of more modern, more efficient methods. We will see that in some particular cases, the basic solvers still outperform the second category of solvers. 

Let us start with the earlier methods. Those include the direct sparse solvers, which are especially effective in one dimension since then the stiffness matrix is banded and the linear system resulting from the discretization can be solved in a time complexity that is linear in the number of degrees of freedom (as showed in \cite{banded}). In two (or more) dimensions, this method is less effective since the band increases and depends a lot on the numbering of the unknowns. This is particularly true for an unstructured mesh. 

Another early method that has to be mentioned is the Fast Fourier Transform (FFT). Direct solvers based on the FFT are extremely fast even in two or three dimensions. The drawback is that the grid often needs to be regular (even though if some work has shown that it is possible to compute efficiently the FFT for non uniform spacing, for more information see \cite{fft}). In any case, this method does not work for general unstructured meshes. Let us nonetheless note that if the source term is smooth and we have need of an uniform resolution, solvers based on the FFT often outperform by a very large margin any other method. 

The last group of methods in the basic solvers consists of the iterative methods, the most famous of which are the conjugate gradients. This method is very general since it can handle unstructured, non conforming meshes in any dimension but, used on its own, it is not very efficient. This problem can be overcome by the addition of a preconditioner. A lot of different preconditioning techniques have been developed with more or less success. The idea is always to reduce the condition number of the stiffness matrix. The performances of the preconditioned conjugate gradients (PCG) depend a lot on the choice of the preconditioner. 


The second category of solvers were developed because the size of the problems became too large for classical iterative methods. It was now needed to have an accurate solution even for systems with trillions of unknowns on very general geometries. We therefore look at methods that can scale to that number of unknowns.  

The second reason is that the solutions of the problems often have very different behavior in different parts of the computational domain. Using an uniform resolution is therefore a lot less efficient that using an adaptive mesh. The second category methods therefore also need to handle non conforming meshes. 

A first example of those methods is the Domain Decomposition (DD), where one split the computational domain into several subdomains. The subdomains can be overlapping, such as in the overlapping additive Schwarz method (OAS) or its multiplicative counterpart (OMS). The subdomains can also be non-overlapping, such as in the balancing domain decomposition method (BDD). The domain decomposition methods can be used by themselves (for example if we can identify two regions where we can use regular grids and the FFT) but are more typically used as preconditioners for the PCG, as it is the case in our application. We can also mention that a coarse problem where we have only a few unknowns by subdomains is very often used to coordinate the solution globally. 

Another very important method is the Geometric Multigrid Method (GMG), where we define an hierarchy of grids and where we solve recursively the problem on coarser and coarser meshes. Those methods have proven very efficient and have been generalized to high-order methods on general unstructured, non conforming meshes. The major difficulty is to define the hierarchy. That is why it is often implemented with an AMR that uses a tree-based method in its refinement process. Even if the geometric multigrid method was initially built for low order discretizations, it has successfully been generalized to higher-order methods (see for example \cite{multi_high}). We can then use a GMG solver with high order on its own or use a GMG solver with a low order as a solver for the coarse problem used in domain decomposition. The latter approach is the one implemented in this thesis. 

A close cousin to GMG is the Algebraic Multigrid Method (AMG) which use the same principles but directly applied to the fine scale matrix. The principal advantage over GMG is that there is no need of a hierarchy of meshes and therefore the method is more flexible (as exemplified in \cite{flexiAlg} or \cite{amg}). The downside is that it often requires more memory and it is generally less efficient than the geometric multigrid method. 

A last method we can mention is Fast Multipole Method. It was initially developed to solve the particle N-body problem but it has been successfully adapted to the Poisson's equation (see \cite{fmm1} and \cite{fmm2} for information). In practice, this method has proven as efficient as GMG.

In addition of the different restrictions presented above, the algorithms also need to be highly parallelizable. Indeed, we want to be able to use millions (or even billions) of CPU cores. Thus, only methods that have a good scalability performs well on such systems.

A comparative study of the efficiency of the different methods presented here has been realized in paper \cite{compa}. They compare state of the art solvers implementing FFT, FMM, GMG and AMG on different problems. Several conclusions are worth mentioning here. For uniform grids, FFT outperforms all other methods by a very large margin. However, for solutions that have very local features, FFT loses to methods that can use adaptive refinement such as GMG and FMM. That is because those methods can use several orders of magnitude fewer unknowns than FFT. Let us also mention that low order variants of any method are always significantly slower than their high order counterparts when the accuracy requirements are high.  

We can end this chapter by saying that no method rules the others. Each method has a particular case for which they are better suited than everybody else. A robust solver should be a hybrid method to handle both cases when the solution is a superposition of oscillatory modes and when we have a highly localized forcing term.



 

